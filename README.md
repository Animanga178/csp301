<h1 align="center">
    "Where's Wally?" with Machine Learning
</h1>

<h4 align="center">A dissertation exploring the impact of machine learning and attention-based saliency detection on classic "Where's Wally?" scenes.</h4>

<p align="center">
  <a href="#key-features">Key Features</a> â€¢
  <a href="#how-to-use">How To Use</a> â€¢
  <a href="#requirements">Requirements</a> â€¢
  <a href="#credits">Credits</a> â€¢
  <a href="#related-works">Related Works</a> â€¢
  <a href="#license">License</a>
</p>

## Key Features

This project was structured into four development phases, each representing an evolution in visual recognition technique:

1. **Phase 1 - CNN (Convolutional Neural Network):** Basic image classification and bounding box prediction.
2. **Phase 2 - R-CNN (Region-based CNN):** Selective search with CNN-based region classification.
3. **Phase 3 - Faster R-CNN:** End-to-end object detection using Region Proposal Networks.
4. **Phase 4 - Saliency Mapping with DeepGaze II-E:** Prediction of human-like visual attention maps over "Where's Wally?" scenes.

The repository includes:
- ðŸ““ Jupyter Notebooks for Phases 1â€“3 (Colab/VSCode compatible)
- ðŸ§  Python scripts and configuration files for Phase 4

Tools used:
- ðŸ§° PyTorch, torchvision, and OpenCV
- ðŸ“Ž Google Colab for GPU training/testing
- ðŸ§ª Visual Studio Code for local experimentation

## How to use

To run this project on your local machine:

1. Clone the Repository
```bash
git clone https://github.com/Animanga178/csp301.git
```
## Requirements

- Python 3.8+
- Google Colab or Jupyter
- Recommended: GPU access for model training


## Credits

* Cite Faster R-CNN used
* Cite pytorch's engine tools stuff
* Cite DeepGaze IIE
   
## Related Works



## License

This project is licensed under the [MIT License](LICENSE).
